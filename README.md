# AI-Dialogue-Evaluation-Coursework

This project was completed as part of *CMPUT 200: Ethics of Data Science and Artificial Intelligence* at the University of Alberta.  
Our team analyzed the ethical implications of using AI in healthcare through a structured dialogue exercise and a comparative evaluation with ChatGPT-generated responses.

- > **Note:** This project was completed collaboratively with five peers (Jerry Xu, Seth Close, Shreya Sethi, and Taehun Lee) as part of the University of Alberta course *CMPUT 200: Ethics of Data Science and Artificial Intelligence* (Winter 2025).  
> The repository is shared for portfolio purposes only to demonstrate AI dialogue evaluation, teamwork, and ethical reasoning skills.

## Overview
The project explored whether AI systems should be used in medical decision-making, focusing on issues such as:
- Data bias and inequality in decision making  
- Privacy and data security  
- Unexplainable decision-making and accountability  

We wrote human-authored arguments and compared them with LLM-generated dialogues from ChatGPT to assess:
- **Coherence**  
- **Tone and bias**  
- **Ethical reasoning**  
- **Alignment with learning outcomes**

- ## 👩‍💻 My Contribution
- Wrote the section on how complex algorithms can lead to *unexplainable decision-making* and the resulting *ethical and legal concerns*.  
- Co-created the presentation comparing human-written and ChatGPT-generated dialogues.  
- Evaluated AI responses for coherence, depth, and alignment with course learning outcomes.  

## 🧩 Skills Demonstrated
- AI dialogue evaluation and qualitative analysis  
- Critical thinking and ethical reasoning  
- Collaboration and academic writing  
- Understanding of bias, interpretability, and accountability in AI systems  

## 📂 Contents
- `Report_Group1_1768166.pdf` – Human-written dialogue (Part A)  
- `CMPUT_200_Dialogues_Part_B.pdf` – Comparative analysis of ChatGPT-generated dialogues (Part B)  
- `200_Presentation.pdf` – Presentation summarizing findings
